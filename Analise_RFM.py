# -*- coding: utf-8 -*-
"""RID182940_Desafio 5 - DNC

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-4M4OY0AvMqpfOakTdysdqO3bVwgYPtJ
"""

!pip install pandas-profiling==3.3.0

!pip install --upgrade numba==0.58.1 visions==0.7.5

import pandas as pd
import numpy as np
from pandas_profiling import ProfileReport

import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("data.csv", encoding='latin-1') # or encoding='cp1252'
display(df)

df.describe()

ProfileReport(df)

"""# Algumas novas observações sobre os dados

- Temos linhas com valores negativos na coluna "quantity".
- Temos linhas com valores "0" em UnitPrice.
- Temos muitas linhas (25% dos dados) faltando (NaN) na coluna Costumer ID.
- Temos 4879 linhas duplicadas, conforme o relatório do Pandas Profiling.
- Temos 1454 linhas faltando na coluna "Description".

Também temos os formatos dos dados:
- InvoiceNo = categorical
- StockCode = categorical
- Description = Categorical
- Quantity = Número Real
- InvoicDate = Categorical
- UnitPrice = Número Real
- CostumerID = Número Real
- Country = Categorical

# Raciocínios

- Valores negativos em quantity podem ser erro de digitação e preciso ou remover, ou alterar esses dados. Se não forem erros de digitação e eu alterar esses dados, vou alterar em muito o resultado das análises. Acho mais seguro remover.
- Valores zero em unitprice podem significar brindes. Não vou excluir esses valores porque não vão alterar o cálculo de valor monetário ou frequência.
- Ausência de 25% dos dados de costumerID é muito prejudicial. Não há possibilidade de encontrar o id do cliente de outra forma, então só me resta apagar as linhas com valores faltantes nessa coluna já que isso torna os dados alí inúteis.
- Linhas duplicadas podem também ser erros de digitação. Seria uma possibilidade considerar elas várias "ordens" de pedidos para cada compra. Mas qual a chance disso acontecer? Deixar esses dados duplicados pode alterar muito a análise. Logo, acho melhor remover as duplicatas.
- A coluna description não é relevante para a análise, ainda mais considerando que temos os códigos de estoque para cada produto. Posso excluir ela.
- Preciso alterar os tipos de dados de cada coluna.

# Conclusões

1. Valores Negativos em "Quantity":
- Possíveis retornos o cancelamentos.
  Depois de analisar melhor, percebi que os valores em que quantidades eram negativas estavam associadas a códigos de faturamento começando com C, o que me fez pensar que são devoluções e cancelamentos.
  Conclusão: Vou manter os registros negativos, ajustar o valor monetario e subtraindo o valor das devoluções do total gasto pelo cliente.
2. Valores Zero em UnitPrice:
- Possíveis brindes ou erros.
  Se forem brindes associados a compras, vale a pena deixar. Mas analisando alguns códigos de faturamento, não necessariamente estavam relacionados a uma compra. Mantê-los pode distorcer a média da análise monetária e a frequência, caso seja um brinde que não esteja relacionada a uma compra.
  Conclusão: Pode ser mais seguro remover esses dados.
3. Ausência de 25% dos dados de CostumerID
- Não temos o que fazer, vamos excluir as linhas sem identificação do cliente.
4. Linhas duplicadas
- Remover as linhas duplicadas.
5. Coluna description
- Pode ser útil em análises futuras, mas para o que tenho idealizado não aparenta ser útil. Vou remover.
6. Alterar os tipos de dados.
"""

df_original = df.copy()

# Contar o número de linhas com UnitPrice igual a zero
num_zero_unitprice = (df['UnitPrice'] == 0).sum()
print(f"Número de linhas com UnitPrice igual a zero: {num_zero_unitprice}")

# Manter apenas as linhas onde UnitPrice é maior que zero
df = df[df['UnitPrice'] > 0]

# Verificar se ainda existem linhas com UnitPrice igual a zero
if (df['UnitPrice'] == 0).any():
    print("Ainda existem linhas com UnitPrice igual a zero.")
else:
    print("Todas as linhas com UnitPrice igual a zero foram removidas.")

# Contar o número de registros com CustomerID ausente
num_missing_customerid = df['CustomerID'].isna().sum()
print(f"Número de registros com CustomerID ausente: {num_missing_customerid}")

df = df.dropna(subset=['CustomerID'])
# Resetar o índice do DataFrame
df = df.reset_index(drop=True)


# Verificar se ainda existem registros com CustomerID ausente
if df['CustomerID'].isna().any():
    print("Ainda existem registros com CustomerID ausente.")
else:
    print("Todos os registros com CustomerID ausente foram removidos.")

# Verificar o número de linhas duplicadas
num_duplicated = df.duplicated().sum()
print(f"Número de linhas duplicadas: {num_duplicated}")

# Identificar todas as linhas duplicadas considerando todas as colunas
duplicated_rows = df[df.duplicated(keep=False)].sort_values(by="StockCode", ascending=True)

# Exibir as primeiras 10 duplicatas
print(duplicated_rows.head(10))

# Remover as linhas duplicadas
df = df.drop_duplicates()

# Resetar o índice do DataFrame
df = df.reset_index(drop=True)

# Verificar novamente o número de linhas duplicadas
num_duplicated_after = df.duplicated().sum()
print(f"Número de linhas duplicadas após remoção: {num_duplicated_after}")

# Convertendo tipos de dados

df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])
df['InvoiceNo'] = df['InvoiceNo'].astype(str)
df['StockCode'] = df['StockCode'].astype(str)
df['Quantity'] = df['Quantity'].astype(int)
df['CustomerID'] = df['CustomerID'].astype(int)
df['UnitPrice'] = df['UnitPrice'].astype(float)
df['Country'] = df['Country'].astype(str)

print(df.dtypes)

# Criando coluna TotalPrice
df['TotalPrice'] = df['Quantity'] * df['UnitPrice']

# Exibir estatísticas descritivas de 'TotalPrice'
print(df['TotalPrice'].describe())

"""Observamos valores mínimos e máximos muito distantes, podendo ser indicativo de outliers."""

plt.figure(figsize=(10, 6))
sns.boxplot(x=df['TotalPrice'])
plt.title('Boxplot de TotalPrice')
plt.show()

# Realmente temos 3 outliers positivos e negativos. Vamos visualizá-los

# Definir um limite superior baseado no percentil 99
limite_superior = df['TotalPrice'].quantile(0.99)
# Exibir registros com TotalPrice acima do limite superior
high_totalprice = df[df['TotalPrice'] > limite_superior].groupby('InvoiceNo').agg({'TotalPrice': 'sum'}).reset_index().sort_values("InvoiceNo", ascending=True)
print(high_totalprice.head(30))

# Definir um limite inferior baseado no percentil 1
limite_inferior = df['TotalPrice'].quantile(0.01)

# Exibir registros com TotalPrice abaixo do limite inferior
low_totalprice = df[df['TotalPrice'] < limite_inferior].groupby('InvoiceNo').agg({'TotalPrice': 'sum'}).reset_index().sort_values("InvoiceNo", ascending=True)
print(low_totalprice.head(30))

"""# Outliers
A existência de outliers simétricos me fez pensar que foram pedidos feitos equivocadamente e posterior cancelamento.

Mas ao fazer a contagem das quantidades canceladas e quantidades pedidas, bem como os valores dos pedidos feitos e cancelados, vi que são valores diferenteS, o que me levou a crer que a simetria dos outliers positivos e negativos foi uma estranha coincidência.

Considerando isso, também tive que levar em consideração que grandes compras e cancelamentos são relevantes para as análises.

Por isso, resolvi deixar os outliers, incluir os cancelamentos e ajustar as métricas.
"""

# Marcar transações de cancelamento
df['IsCancellation'] = df['InvoiceNo'].str.startswith('C')

# Calcular o valor monetário líquido por cliente
monetary = df.groupby('CustomerID').agg({
    'TotalPrice': lambda x: x[df['IsCancellation'] == False].sum() + x[df['IsCancellation'] == True].sum()
}).reset_index()
monetary.rename(columns={'TotalPrice': 'Monetary'}, inplace=True)

df.sort_values("TotalPrice", ascending=True).head(20)

df.sort_values("TotalPrice", ascending=False).head(20)

# Ordenar o DataFrame por 'CustomerID' e 'InvoiceDate'
df = df.sort_values(by=['CustomerID', 'InvoiceDate'])

# Criar uma chave única combinando colunas relevantes
df['Key'] = df['CustomerID'].astype(str) + '_' + \
            df['UnitPrice'].astype(str) + '_' + \
            df['InvoiceDate'].dt.strftime('%Y-%m-%d').astype(str)

df.head()

# Agrupar por Key e somar Quantity e TotalPrice
grouped = df.groupby('Key').agg({
    'Quantity': 'sum',
    'TotalPrice': 'sum',
    'CustomerID': 'first',
    'UnitPrice': 'first',
    'InvoiceDate': 'first'
}).reset_index()

# Identificar chaves onde a soma de TotalPrice é zero
keys_to_remove = grouped[grouped['TotalPrice'] == 0]['Key']

# Remover registros com as chaves identificadas
df_cleaned = df[~df['Key'].isin(keys_to_remove)].reset_index(drop=True)

df_cleaned.sort_values("TotalPrice", ascending=True).head(20)

df_cleaned.sort_values("TotalPrice", ascending=False).head(20)

# Verificar os índices do DataFrame
print(df_cleaned.index)
print(df_cleaned.index.dtype)

# Removendo Cancelamentos Restantes

df_cleaned.drop([197866, 197865, 237503, 237508, 237501, 237494, 237498, 237499], axis=0, inplace=True)

df_cleaned.sort_values("TotalPrice", ascending=False).head(20)

df_cleaned['TotalPrice'].describe()

plt.figure(figsize=(10, 6))
sns.boxplot(x=df_cleaned['TotalPrice'])
plt.title('Boxplot de TotalPrice')
plt.show()

"""# Sobre outliers

Optei por não fazer o tratamento geral dos outliers com IQR por não querer remover registros legítimos de valores altos.

Existem novos valores outliers agora, o que é normal. Mas considerando a análise RFM, sendo valores legítimos, são válidos de permanecerem.

Com o novo boxplot conseguimos ter novas percepções, como exemplo, é visível que o número de cancelamentos, apesar de grande, tem uma proporção de aparente um terço em relação aos pedidos.
"""

# Top 10 Países com Maior Valor em Vendas
# Agrupar por 'Country' e somar 'TotalPrice'
vendas_por_pais = df_cleaned.groupby('Country')['TotalPrice'].sum().reset_index()

# Ordenar de forma decrescente e selecionar os top 10
top10_paises = vendas_por_pais.sort_values(by='TotalPrice', ascending=False).head(10)

# Configurar o estilo do gráfico
sns.set(style="whitegrid")

# Criar o gráfico de barras
plt.figure(figsize=(12, 8))
sns.barplot(x='TotalPrice', y='Country', data=top10_paises, palette='viridis')

# Adicionar títulos e rótulos
plt.title('Top 10 Países com Maior Valor em Vendas', fontsize=16)
plt.xlabel('Valor Total de Vendas', fontsize=14)
plt.ylabel('País', fontsize=14)

# Exibir os valores nas barras
for index, value in enumerate(top10_paises['TotalPrice']):
    plt.text(value, index, f'R${value:,.2f}', va='center')

plt.tight_layout()
plt.show()

# Top 10 Produtos Mais Vendidos
# Agrupar por 'Description' e somar 'Quantity'
vendas_por_produto = df_cleaned.groupby('Description')['Quantity'].sum().reset_index()

# Ordenar de forma decrescente e selecionar os top 10
top10_produtos = vendas_por_produto.sort_values(by='Quantity', ascending=False).head(10)

# Configurar o estilo do gráfico
sns.set(style="whitegrid")

# Criar o gráfico de barras
plt.figure(figsize=(12, 8))
sns.barplot(x='Quantity', y='Description', data=top10_produtos, palette='magma')

# Adicionar títulos e rótulos
plt.title('Top 10 Produtos Mais Vendidos', fontsize=16)
plt.xlabel('Quantidade Vendida', fontsize=14)
plt.ylabel('Produto', fontsize=14)

# Exibir os valores nas barras
for index, value in enumerate(top10_produtos['Quantity']):
    plt.text(value, index, f'{value:,}', va='center')

plt.tight_layout()
plt.show()

# Valor de Venda Total por Mês
# Certificar-se de que 'InvoiceDate' está em datetime
df_cleaned['InvoiceDate'] = pd.to_datetime(df_cleaned['InvoiceDate'])

# Extrair mês e ano
df_cleaned['Ano_Mes'] = df_cleaned['InvoiceDate'].dt.to_period('M').astype(str)

# Agrupar por 'Ano_Mes' e somar 'TotalPrice'
vendas_por_mes = df_cleaned.groupby('Ano_Mes')['TotalPrice'].sum().reset_index()

# Ordenar cronologicamente
vendas_por_mes = vendas_por_mes.sort_values('Ano_Mes')

# Configurar o estilo do gráfico
sns.set(style="whitegrid")

# Criar o gráfico de linha
plt.figure(figsize=(14, 7))
sns.lineplot(x='Ano_Mes', y='TotalPrice', data=vendas_por_mes, marker='o', color='blue')

# Adicionar títulos e rótulos
plt.title('Valor de Venda Total por Mês', fontsize=16)
plt.xlabel('Mês/Ano', fontsize=14)
plt.ylabel('Valor Total de Vendas', fontsize=14)

# Rotacionar os rótulos do eixo x para melhor visualização
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

# Valor de Venda Total por Mês e por País (Top 10 Países)
# Supondo que 'top10_paises' já está definido a partir do gráfico 1

# Lista dos top 10 países
lista_top10_paises = top10_paises['Country'].tolist()

# Filtrar o DataFrame para incluir apenas os top 10 países
df_top10_paises = df_cleaned[df_cleaned['Country'].isin(lista_top10_paises)].copy()

# Extrair mês e ano
df_top10_paises['Ano_Mes'] = df_top10_paises['InvoiceDate'].dt.to_period('M').astype(str)

# Agrupar por 'Ano_Mes' e 'Country' e somar 'TotalPrice'
vendas_top10_mes_pais = df_top10_paises.groupby(['Ano_Mes', 'Country'])['TotalPrice'].sum().reset_index()

# Ordenar cronologicamente
vendas_top10_mes_pais = vendas_top10_mes_pais.sort_values('Ano_Mes')

# Configurar o estilo do gráfico
sns.set(style="whitegrid")

# Criar o gráfico de linhas múltiplas
plt.figure(figsize=(16, 10))
sns.lineplot(data=vendas_top10_mes_pais, x='Ano_Mes', y='TotalPrice', hue='Country', marker='o')

# Adicionar títulos e rótulos
plt.title('Valor de Venda Total por Mês e por País (Top 10 Países)', fontsize=18)
plt.xlabel('Mês/Ano', fontsize=14)
plt.ylabel('Valor Total de Vendas', fontsize=14)

# Rotacionar os rótulos do eixo x para melhor visualização
plt.xticks(rotation=45)

# Melhorar a legenda
plt.legend(title='País', bbox_to_anchor=(1.05, 1), loc='upper left')

plt.tight_layout()
plt.show()

# Alternativa Gráfico de Barras Empilhadas
# Pivotar os dados para ter países como colunas
vendas_pivot = vendas_top10_mes_pais.pivot(index='Ano_Mes', columns='Country', values='TotalPrice').fillna(0)

# Configurar o estilo do gráfico
sns.set(style="whitegrid")

# Criar o gráfico de barras empilhadas
vendas_pivot.plot(kind='bar', stacked=True, figsize=(16, 10), colormap='tab20')

# Adicionar títulos e rótulos
plt.title('Valor de Venda Total por Mês e por País (Top 10 Países)', fontsize=18)
plt.xlabel('Mês/Ano', fontsize=14)
plt.ylabel('Valor Total de Vendas', fontsize=14)

# Rotacionar os rótulos do eixo x para melhor visualização
plt.xticks(rotation=45)

# Melhorar a legenda
plt.legend(title='País', bbox_to_anchor=(1.05, 1), loc='upper left')

plt.tight_layout()
plt.show()

# Determinar a data máxima no conjunto de dados limpo
max_date = df_cleaned['InvoiceDate'].max()
print(f"Data máxima atualizada: {max_date}")

# Calcular Recência (R)
recency = df_cleaned.groupby('CustomerID').agg({
    'InvoiceDate': lambda x: (max_date - x.max()).days
}).reset_index()
recency.rename(columns={'InvoiceDate': 'Recency'}, inplace=True)

# Calcular Frequência (F) - Apenas compras efetivas
frequency = df_cleaned[~df_cleaned['IsCancellation']].groupby('CustomerID').agg({
    'InvoiceNo': 'nunique'
}).reset_index()
frequency.rename(columns={'InvoiceNo': 'Frequency'}, inplace=True)

# Calcular Valor Monetário (M) - Compras menos cancelamentos
monetary = df_cleaned.groupby('CustomerID').agg({
    'TotalPrice': 'mean'
}).reset_index()
monetary.rename(columns={'TotalPrice': 'Monetary'}, inplace=True)

# Combinar as métricas RFM
rfm = recency.merge(frequency, on='CustomerID').merge(monetary, on='CustomerID')

# Exibir as primeiras linhas do DataFrame RFM
print("Métricas RFM calculadas:")
print(rfm.head())

df_cleaned.groupby('CustomerID').mean('TotalPrice')

# Exibir estatísticas descritivas das métricas RFM
print("Estatísticas descritivas das métricas RFM:")
print(rfm.describe())

# Configurar o estilo dos gráficos
sns.set(style="whitegrid")

# Boxplots das métricas RFM
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
sns.boxplot(y=rfm['Recency'])
plt.title('Recency')

plt.subplot(1, 3, 2)
sns.boxplot(y=rfm['Frequency'])
plt.title('Frequency')

plt.subplot(1, 3, 3)
sns.boxplot(y=rfm['Monetary'])
plt.title('Monetary')

plt.tight_layout()
plt.show()

# Histogramas das métricas RFM
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
sns.histplot(rfm['Recency'], bins=50, kde=True)
plt.title('Distribuição da Recency')

plt.subplot(1, 3, 2)
sns.histplot(rfm['Frequency'], bins=50, kde=True)
plt.title('Distribuição da Frequency')

plt.subplot(1, 3, 3)
sns.histplot(rfm['Monetary'], bins=50, kde=True)
plt.title('Distribuição da Monetary')

plt.tight_layout()
plt.show()

# Definir quantis para cada métrica
quantiles = rfm.quantile(q=[0.2, 0.4, 0.6, 0.8]).to_dict()

def r_score(x, p, d):
    if x <= d[p][0.2]:
        return 5
    elif x <= d[p][0.4]:
        return 4
    elif x <= d[p][0.6]:
        return 3
    elif x <= d[p][0.8]:
        return 2
    else:
        return 1

def fm_score(x, p, d):
    if x <= d[p][0.2]:
        return 1
    elif x <= d[p][0.4]:
        return 2
    elif x <= d[p][0.6]:
        return 3
    elif x <= d[p][0.8]:
        return 4
    else:
        return 5

# Aplicar as funções de pontuação
rfm['R_quartile'] = rfm['Recency'].apply(r_score, args=('Recency', quantiles))
rfm['F_quartile'] = rfm['Frequency'].apply(fm_score, args=('Frequency', quantiles))
rfm['M_quartile'] = rfm['Monetary'].apply(fm_score, args=('Monetary', quantiles))

# Combinar as pontuações para formar o RFM Score
rfm['RFM_Score'] = rfm['R_quartile'].astype(str) + rfm['F_quartile'].astype(str) + rfm['M_quartile'].astype(str)

# Exibir as primeiras linhas com as pontuações
print("Métricas RFM com pontuação:")
print(rfm.head())

"""# Interpretação das Pontuações:

Recência (R): Clientes com menor recência (compras mais recentes) recebem pontuação mais alta (5).

Frequência (F): Clientes que compram mais frequentemente recebem pontuação mais alta (5).

Monetário (M): Clientes que gastam mais por compra recebem pontuação mais alta (5).

---

# Exemplo de Segmentação:


Segmento 555: Melhores clientes (alta recência, alta frequência, alto valor monetário).

Segmento 111: Clientes menos valiosos (baixa recência, baixa frequência, baixo valor monetário).

Outros segmentos: Variações intermediárias que representam diferentes níveis de engajamento e valor.

---
# Sugestões a seguir:

Analisar os Segmentos

Identifique quais segmentos têm maior potencial para campanhas específicas.
Desenvolva estratégias de marketing direcionadas para cada segmento.
"""

# Salvar o DataFrame RFM com pontuações em um arquivo CSV
rfm.to_csv('rfm_output.csv', index=False)
print("Arquivo 'rfm_output.csv' salvo com sucesso!")

